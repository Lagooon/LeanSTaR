`apex` is not installed. Reverting to non-fused RMSNorm.
Loading model ...
INFO 04-27 18:10:06 llm_engine.py:87] Initializing an LLM engine with config: model='/nobackup/users/zhiqings/haohanl/Lean/checkpoints/internlm/internlm2-math-base-7b/cots', tokenizer='/nobackup/users/zhiqings/haohanl/Lean/checkpoints/internlm/internlm2-math-base-7b/cots', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
INFO 04-27 18:10:23 llm_engine.py:357] # GPU blocks: 0, # CPU blocks: 2048
Traceback (most recent call last):
  File "/nobackup/users/zhiqings/haohanl/LeanCOT/gpt-fast/cot_search.py", line 1014, in <module>
    main(
  File "/nobackup/users/zhiqings/haohanl/LeanCOT/gpt-fast/cot_search.py", line 645, in main
    model, tokenizer = _load_model(checkpoint_path, device, precision, tp_size)
  File "/nobackup/users/zhiqings/haohanl/LeanCOT/gpt-fast/cot_search.py", line 254, in _load_model
    model = vllm.LLM(
  File "/nobackup/users/zhiqings/haohanl/lean1/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 109, in __init__
    self.llm_engine = LLMEngine.from_engine_args(engine_args)
  File "/nobackup/users/zhiqings/haohanl/lean1/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 391, in from_engine_args
    engine = cls(*engine_configs,
  File "/nobackup/users/zhiqings/haohanl/lean1/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 131, in __init__
    self._init_cache()
  File "/nobackup/users/zhiqings/haohanl/lean1/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 361, in _init_cache
    raise ValueError("No available memory for the cache blocks. "
ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
