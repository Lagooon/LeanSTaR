# tests with BPE tokenizer

from transformers import AutoTokenizer

ds_math_model_name = "deepseek-ai/deepseek-math-7b-base"
tokenizer = AutoTokenizer.from_pretrained(ds_math_model_name)

tests = [
    "",
    " ",
    "  ",
    "   ",
    "\t",
    "\n",
    "\t\n",
    "\n\nHello",
    "Hello Hello",
    "Hello world",
    " Hello world",
    "Hello World",
    " Hello World",
    " Hello World!",
    "Hello, world!",
    " Hello, world!",
    " this is ğŸ¦™.cpp",
    "w048 7tuijk dsdfhu",
    "Ğ½ĞµÑ‰Ğ¾ Ğ½Ğ° Ğ‘ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸",
    "á€á¶á“áŸ‹ááŸ‚á–á·áŸáŸáŸá¢á¶á…áá›á…áŸá‰",
    "ğŸš€ (normal) ğŸ˜¶â€ğŸŒ«ï¸ (multiple emojis concatenated) âœ… (only emoji that has its own token)",
    "Hello",
    " Hello",
    "  Hello",
    "   Hello",
    "    Hello",
    "    Hello\n    Hello",
    "\n =",
    "' era",
    "Hello, y'all! How are you ğŸ˜ ?æˆ‘æƒ³åœ¨appleå·¥ä½œ1314151å¤©ï½",
]

for text in tests:
    print("text: ", [text])
    print(tokenizer.encode(text))
    print([tokenizer.decode(tokenizer.encode(text), skip_special_tokens=True)])
